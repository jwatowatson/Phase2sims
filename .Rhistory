Sample_sizes = seq(20,100,by=10)
Effect_sizes = c(1.05,1.075,1.1,1.15,1.2,1.25)
Max_follows = c(7,10,14) # Follow-up durations
Nsim = 10 # number of trials
my_alpha = 0.05 # significance level to compute type 2 error
FORCE_RE_RUN
FORCE_RE_RUN = T
out_path = 'Rout/power_summaries.RData'
if(FORCE_RE_RUN | !file.exists(out_path)){
power_summaries = list(); j = 1
for(i in 1:length(Max_follows)){
pp1 = compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follows[i],
Nsim = Nsim,
summary_function = compute_clearance_time,
thetas=thetas, endpoint = 'timetoevent')
pp2 = compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follows[i],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')
power_summaries[[j]] = pp1; j = j+1;
power_summaries[[j]] = pp2; j = j+1;
}
save(power_summaries, file = out_path)
} else {
load(out_path)
}
# compute average 1 - type 2 error
power_list = lapply(power_summaries,
function(ll) apply(ll, 1:2, function(x) mean(x<my_alpha)))
cols=RColorBrewer::brewer.pal(7,'Dark2')[c(4,1)]
my_cols = rep(cols, length(Max_follows))
my_ltys = foreach(x = 1:length(Max_follows), .combine = c) %do% rep(x,2)
par(mfrow=c(2,3),las=1,lwd=1.5, cex.lab=1.3,cex.axis=1.3,family='serif',mar=c(5,5,3,2),bty='n')
for(i in 1:length(Effect_sizes)) {
plot(Sample_sizes, power_list[[1]][i,], ylim = c(0,1),type='l',
xlab='Sample size per arm',ylab='Power',col=my_cols[1], lty=my_ltys[1])
for(j in 2:length(power_list)){
lines(Sample_sizes, power_list[[j]][i,], col=my_cols[j], lty=my_ltys[j])
}
title(paste(100*(Effect_sizes[i]-1),'%',sep=''))
if(i==1){
legend('topleft',col=c(cols, rep('black',length(Max_follows))),bty='n',
lty=c(1,1,1:length(Max_follows)),inset=0.03,title = 'Endpoint',
legend = c('Time to clearance','Rate of clearance'))
legend('left',col='black',title = 'Duration of follow-up (days)',
lty=1:length(Max_follows),inset=0.03,bty='n',
legend = Max_follows)
}
}
Effect_sizes = 1.075
follow_days = lapply(c(0.5,1,2,5,10), function(x) seq(0,10,by=x))
power_rates = list()
out_path = 'Rout/frequency_follow_up.RData'
load(out_path)
summaries = lapply(power_rates, function(x) apply(x,1,
function(x) mean(x<my_alpha)))
par(mfrow=c(1,1),las=1,cex.lab=1.3,
cex.axis=1.3,family='serif',mar=c(5,5,3,2),bty='n')
mycols = RColorBrewer::brewer.pal(length(summaries), name = 'BrBG')
plot(Sample_sizes, summaries[[1]],type='l', col=mycols[1],panel.first=grid(),
ylab='Power', xlab= 'Sample size per arm', ylim=c(0,1),lwd=3)
for(i in 2:length(summaries)){
lines(Sample_sizes, summaries[[i]],col=mycols[i],lwd=3)
}
legend('bottomright',legend = sapply(follow_days,length),col=mycols,cex=1.5,
inset=0.03,lwd=3, title='Viral load measurements over 10 days',bty='n')
Effect_sizes = 1.075
Sample_sizes = 50
Max_follow = seq(3, 21, by=1)
out_path = 'Rout/duration.RData'
if(FORCE_RE_RUN){
power_TE_follow = power_rates_follow = array(dim = c(length(Max_follow), Nsim))
# do for rate endpoint
for(mm in 1:length(Max_follow)){
power_rates_follow[mm,]=
compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follow[mm],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')[1,1,,drop=T]
}
# do for time to event endpoint
for(mm in 5:length(Max_follow)){
power_TE_follow[mm,]=
compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follow[mm],
Nsim = Nsim,
summary_function = compute_clearance_time,
thetas=thetas, endpoint = 'timetoevent')[1,1,,drop=T]
}
save(power_rates_follow, power_TE_follow, file = out_path)
} else {
load(file = out_path)
}
par(mfrow=c(1,1),las=1,lwd=1.5, cex.lab=1.3,cex.axis=1.3,family='serif',mar=c(5,5,3,2),bty='n')
plot(Max_follow, apply(power_rates_follow, 1, function(x) mean(x<my_alpha)),
type='l', ylim = c(0,1), ylab='Power',panel.first=grid(),
xlab= 'Duration of follow-up',col=cols[2])
lines(Max_follow,apply(power_TE_follow, 1, function(x) mean(x<my_alpha)),col=cols[1])
abline(h=c(0.6,.44),v=c(10,12),lty=2)
legend('topright',legend = c('Time-to-clearance', 'Rate-of-clearance'),
col=cols,lwd=2, title = 'Endpoint', bty='n')
out_path = 'Rout/frequency_follow_up.RData'
file.exists(out_path)
knitr::opts_chunk$set(cache = TRUE, cache.comments = FALSE,
include = TRUE, echo = TRUE,
fig.width = 9, fig.height = 9,
fig.pos = 'H',
dev = 'png', dpi = 300)
library(doParallel)
library(tictoc)
library(rstan)
library(RColorBrewer)
library(survival)
doParallel::registerDoParallel(cores = 8)
FORCE_RE_RUN = T
# set of functions for the simulations
source('functions.R')
# get posterior samples from the pharmacodynamic model
load('Rout/stan_out_rate.RData')
### Figure to demonstrate what the model looks like
sim_dat_null = simulate_data(N = 10^4, effect = 1, thetas = thetas, xs = 0:21)
sim_dat_5 = simulate_data(N = 10^4, effect = 1.05, thetas = thetas, xs = 0:21)
sim_dat_75 = simulate_data(N = 10^4, effect = 1.075, thetas = thetas, xs = 0:21)
sim_dat_15 = simulate_data(N = 10^4, effect = 1.15, thetas = thetas, xs = 0:21)
sim_dat_25 = simulate_data(N = 10^4, effect = 1.25, thetas = thetas, xs = 0:21)
par(las = 1, mfrow=c(2,2), family='serif', bty='n',cex.axis=1.3,cex.lab=1.3)
set.seed(485)
plot(0:21, sim_dat_null[1,], col = adjustcolor('grey',.3),type='l',ylim = c(40,13),
ylab='Ct',xlab = 'Days since peak viral load')
points(0:21, sim_dat_null[1,], pch='.')
cols = RColorBrewer::brewer.pal(n = 11, name = 'Set3'); j = 1
for(i in sample(0:1000, 9)){
lines(0:21, sim_dat_null[i,], col = adjustcolor(cols[j%%11 + 1],.4))
points(0:21, sim_dat_null[i,], pch='.')
j = j+1
}
cols = rev(RColorBrewer::brewer.pal(n = 5, name = 'RdYlBu'))
plot(0:21, colMeans(sim_dat_null), type='l', ylab='Ct', col=cols[1],
xlab = 'Days since peak viral load', ylim = c(40,13),lwd=2)
lines(0:21, colMeans(sim_dat_5),col=cols[2],lwd=2)
lines(0:21, colMeans(sim_dat_75),col=cols[3],lwd=2)
lines(0:21, colMeans(sim_dat_15),col=cols[4],lwd=2)
lines(0:21, colMeans(sim_dat_25),col=cols[5],lwd=2)
legend('topright', legend = c(0,5,7.5,15,25),col=cols, bty='n',
inset=0.03,lwd=3, title = 'Effect size (%)')
rates_15 = compute_rate(sim_data = sim_dat_15, xs = 0:21)
rates_0 = compute_rate(sim_data = sim_dat_null, xs = 0:21)
plot(density(rates_0), main = '', ylab = '', col = cols[1],lwd=3,
yaxt='n', xaxt='n', xlab='Clearance half-life', xlim = c(3,1))
lines(density(rates_15), col=cols[4], lwd=3)
axis(1, at = seq(1,3,by=.5), labels = 24/seq(1,3,by=.5))
legend('topright', legend = c(0,15),col=cols[c(1,4)], bty='n',
inset=0.03,lwd=3, title = 'Effect size (%)')
TC_0 = compute_clearance_time(sim_dat_null,xs = 0:21)[,1]
TC_15 = compute_clearance_time(sim_dat_15,xs = 0:21)[,1]
plot(density(TC_15[complete.cases(TC_15)], bw = .6),
main = '', ylab = '', col = cols[4],lwd=3,
yaxt='n',  xlab='Clearance time')
lines(density(TC_0[complete.cases(TC_0)],bw = 0.6), col=cols[1], lwd=3)
legend('topright', legend = c(0,15),col=cols[c(1,4)], bty='n',
inset=0.03,lwd=3, title = 'Effect size (%)')
# Parameters for the simulations
Sample_sizes = seq(20,100,by=10)
Effect_sizes = c(1.05,1.075,1.1,1.15,1.2,1.25)
Max_follows = c(7,10,14) # Follow-up durations
Nsim = 2000 # number of trials
my_alpha = 0.05 # significance level to compute type 2 error
out_path = 'Rout/power_summaries.RData'
if(FORCE_RE_RUN | !file.exists(out_path)){
power_summaries = list(); j = 1
for(i in 1:length(Max_follows)){
pp1 = compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follows[i],
Nsim = Nsim,
summary_function = compute_clearance_time,
thetas=thetas, endpoint = 'timetoevent')
pp2 = compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follows[i],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')
power_summaries[[j]] = pp1; j = j+1;
power_summaries[[j]] = pp2; j = j+1;
}
save(power_summaries, file = out_path)
} else {
load(out_path)
}
# compute average 1 - type 2 error
power_list = lapply(power_summaries,
function(ll) apply(ll, 1:2, function(x) mean(x<my_alpha)))
cols=RColorBrewer::brewer.pal(7,'Dark2')[c(4,1)]
my_cols = rep(cols, length(Max_follows))
my_ltys = foreach(x = 1:length(Max_follows), .combine = c) %do% rep(x,2)
par(mfrow=c(2,3),las=1,lwd=1.5, cex.lab=1.3,cex.axis=1.3,family='serif',mar=c(5,5,3,2),bty='n')
for(i in 1:length(Effect_sizes)) {
plot(Sample_sizes, power_list[[1]][i,], ylim = c(0,1),type='l',
xlab='Sample size per arm',ylab='Power',col=my_cols[1], lty=my_ltys[1])
for(j in 2:length(power_list)){
lines(Sample_sizes, power_list[[j]][i,], col=my_cols[j], lty=my_ltys[j])
}
title(paste(100*(Effect_sizes[i]-1),'%',sep=''))
if(i==1){
legend('topleft',col=c(cols, rep('black',length(Max_follows))),bty='n',
lty=c(1,1,1:length(Max_follows)),inset=0.03,title = 'Endpoint',
legend = c('Time to clearance','Rate of clearance'))
legend('left',col='black',title = 'Duration of follow-up (days)',
lty=1:length(Max_follows),inset=0.03,bty='n',
legend = Max_follows)
}
}
FORCE_RE_RUN=F
# Fix effect size
Effect_sizes = 1.075
follow_days = lapply(c(0.5,1,2,5,10), function(x) seq(0,10,by=x))
power_rates = list()
out_path = 'Rout/frequency_follow_up.RData'
if(FORCE_RE_RUN | !file.exists(out_path)){
for(i in 1:length(follow_days)){
writeLines(sprintf('Doing simulation with %s follow-up points',
length(follow_days[[i]])))
power_rates[[i]] = compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = follow_days[[i]],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')[1,,]
}
save(power_rates, file = out_path)
} else {
load(out_path)
}
summaries = lapply(power_rates, function(x) apply(x,1,
function(x) mean(x<my_alpha)))
par(mfrow=c(1,1),las=1,cex.lab=1.3,
cex.axis=1.3,family='serif',mar=c(5,5,3,2),bty='n')
mycols = RColorBrewer::brewer.pal(length(summaries), name = 'BrBG')
plot(Sample_sizes, summaries[[1]],type='l', col=mycols[1],panel.first=grid(),
ylab='Power', xlab= 'Sample size per arm', ylim=c(0,1),lwd=3)
for(i in 2:length(summaries)){
lines(Sample_sizes, summaries[[i]],col=mycols[i],lwd=3)
}
legend('bottomright',legend = sapply(follow_days,length),col=mycols,cex=1.5,
inset=0.03,lwd=3, title='Viral load measurements over 10 days',bty='n')
FORCE_RE_RUN=T
Effect_sizes = 1.075
Sample_sizes = 50
Max_follow = seq(3, 21, by=1)
out_path = 'Rout/duration.RData'
if(FORCE_RE_RUN){
power_TE_follow = power_rates_follow = array(dim = c(length(Max_follow), Nsim))
# do for rate endpoint
for(mm in 1:length(Max_follow)){
power_rates_follow[mm,]=
compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follow[mm],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')[1,1,,drop=T]
}
# do for time to event endpoint
for(mm in 5:length(Max_follow)){
power_TE_follow[mm,]=
compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follow[mm],
Nsim = Nsim,
summary_function = compute_clearance_time,
thetas=thetas, endpoint = 'timetoevent')[1,1,,drop=T]
}
save(power_rates_follow, power_TE_follow, file = out_path)
} else {
load(file = out_path)
}
par(mfrow=c(1,1),las=1,lwd=1.5, cex.lab=1.3,cex.axis=1.3,family='serif',mar=c(5,5,3,2),bty='n')
plot(Max_follow, apply(power_rates_follow, 1, function(x) mean(x<my_alpha)),
type='l', ylim = c(0,1), ylab='Power',panel.first=grid(),
xlab= 'Duration of follow-up',col=cols[2])
lines(Max_follow,apply(power_TE_follow, 1, function(x) mean(x<my_alpha)),col=cols[1])
abline(h=c(0.6,.44),v=c(10,12),lty=2)
legend('topright',legend = c('Time-to-clearance', 'Rate-of-clearance'),
col=cols,lwd=2, title = 'Endpoint', bty='n')
Nsim
Effect_sizes = 1.075
Sample_sizes = 50
Max_follow = seq(3, 21, by=1)
out_path = 'Rout/duration.RData'
Nsim = 10000
if(FORCE_RE_RUN){
power_TE_follow = power_rates_follow = array(dim = c(length(Max_follow), Nsim))
# do for rate endpoint
for(mm in 1:length(Max_follow)){
power_rates_follow[mm,]=
compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follow[mm],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')[1,1,,drop=T]
}
# do for time to event endpoint
for(mm in 5:length(Max_follow)){
power_TE_follow[mm,]=
compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follow[mm],
Nsim = Nsim,
summary_function = compute_clearance_time,
thetas=thetas, endpoint = 'timetoevent')[1,1,,drop=T]
}
save(power_rates_follow, power_TE_follow, file = out_path)
} else {
load(file = out_path)
}
knitr::opts_chunk$set(cache = TRUE, cache.comments = FALSE,
include = TRUE, echo = TRUE,
fig.width = 9, fig.height = 9,
fig.pos = 'H',
dev = 'png', dpi = 300)
library(doParallel)
library(tictoc)
library(rstan)
library(RColorBrewer)
library(survival)
doParallel::registerDoParallel(cores = 8)
FORCE_RE_RUN = F
# set of functions for the simulations
source('functions.R')
# get posterior samples from the pharmacodynamic model
load('Rout/stan_out_rate.RData')
### Figure to demonstrate what the model looks like
sim_dat_null = simulate_data(N = 10^4, effect = 1, thetas = thetas, xs = 0:21)
sim_dat_5 = simulate_data(N = 10^4, effect = 1.05, thetas = thetas, xs = 0:21)
sim_dat_75 = simulate_data(N = 10^4, effect = 1.075, thetas = thetas, xs = 0:21)
sim_dat_15 = simulate_data(N = 10^4, effect = 1.15, thetas = thetas, xs = 0:21)
sim_dat_25 = simulate_data(N = 10^4, effect = 1.25, thetas = thetas, xs = 0:21)
par(las = 1, mfrow=c(2,2), family='serif', bty='n',cex.axis=1.3,cex.lab=1.3)
set.seed(485)
plot(0:21, sim_dat_null[1,], col = adjustcolor('grey',.3),type='l',ylim = c(40,13),
ylab='Ct',xlab = 'Days since peak viral load')
points(0:21, sim_dat_null[1,], pch='.')
cols = RColorBrewer::brewer.pal(n = 11, name = 'Set3'); j = 1
for(i in sample(0:1000, 9)){
lines(0:21, sim_dat_null[i,], col = adjustcolor(cols[j%%11 + 1],.4))
points(0:21, sim_dat_null[i,], pch='.')
j = j+1
}
mtext(text = 'A', side = 3, adj = 0)
cols = rev(RColorBrewer::brewer.pal(n = 5, name = 'RdYlBu'))
plot(0:21, colMeans(sim_dat_null), type='l', ylab='Ct', col=cols[1],
xlab = 'Days since peak viral load', ylim = c(40,13),lwd=2)
lines(0:21, colMeans(sim_dat_5),col=cols[2],lwd=2)
lines(0:21, colMeans(sim_dat_75),col=cols[3],lwd=2)
lines(0:21, colMeans(sim_dat_15),col=cols[4],lwd=2)
lines(0:21, colMeans(sim_dat_25),col=cols[5],lwd=2)
legend('topright', legend = c(0,5,7.5,15,25),col=cols, bty='n',
inset=0.03,lwd=3, title = 'Effect size (%)')
mtext(text = 'B', side = 3, adj = 0)
rates_15 = compute_rate(sim_data = sim_dat_15, xs = 0:21)
rates_0 = compute_rate(sim_data = sim_dat_null, xs = 0:21)
plot(density(rates_0), main = '', ylab = '', col = cols[1],lwd=3,
yaxt='n', xaxt='n', xlab='Clearance half-life', xlim = c(3,1))
lines(density(rates_15), col=cols[4], lwd=3)
axis(1, at = seq(1,3,by=.5), labels = 24/seq(1,3,by=.5))
legend('topright', legend = c(0,15),col=cols[c(1,4)], bty='n',
inset=0.03,lwd=3, title = 'Effect size (%)')
mtext(text = 'C', side = 3, adj = 0)
TC_0 = compute_clearance_time(sim_dat_null,xs = 0:21)[,1]
TC_15 = compute_clearance_time(sim_dat_15,xs = 0:21)[,1]
plot(density(TC_15[complete.cases(TC_15)], bw = .6),
main = '', ylab = '', col = cols[4],lwd=3,
yaxt='n',  xlab = 'Clearance time')
lines(density(TC_0[complete.cases(TC_0)],bw = 0.6), col=cols[1], lwd=3)
legend('topright', legend = c(0,15),col=cols[c(1,4)], bty='n',
inset=0.03,lwd=3, title = 'Effect size (%)')
mtext(text = 'D', side = 3, adj = 0)
# Parameters for the simulations
Sample_sizes = seq(20,100,by=10)
Effect_sizes = c(1.05,1.075,1.1,1.15,1.2,1.25)
Max_follows = c(7,10,14) # Follow-up durations
Nsim = 2000 # number of trials
my_alpha = 0.05 # significance level to compute type 2 error
out_path = 'Rout/power_summaries.RData'
if(FORCE_RE_RUN | !file.exists(out_path)){
power_summaries = list(); j = 1
for(i in 1:length(Max_follows)){
pp1 = compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follows[i],
Nsim = Nsim,
summary_function = compute_clearance_time,
thetas=thetas, endpoint = 'timetoevent')
pp2 = compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follows[i],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')
power_summaries[[j]] = pp1; j = j+1;
power_summaries[[j]] = pp2; j = j+1;
}
save(power_summaries, file = out_path)
} else {
load(out_path)
}
# compute average 1 - type 2 error
power_list = lapply(power_summaries,
function(ll) apply(ll, 1:2, function(x) mean(x<my_alpha)))
cols=RColorBrewer::brewer.pal(7,'Dark2')[c(4,1)]
my_cols = rep(cols, length(Max_follows))
my_ltys = foreach(x = 1:length(Max_follows), .combine = c) %do% rep(x,2)
par(mfrow=c(2,3),las=1,lwd=1.5, cex.lab=1.3,cex.axis=1.3,family='serif',mar=c(5,5,3,2),bty='n')
for(i in 1:length(Effect_sizes)) {
plot(Sample_sizes, power_list[[1]][i,], ylim = c(0,1),type='l',
xlab='Sample size per arm',ylab='Power',col=my_cols[1], lty=my_ltys[1])
for(j in 2:length(power_list)){
lines(Sample_sizes, power_list[[j]][i,], col=my_cols[j], lty=my_ltys[j])
}
title(paste(100*(Effect_sizes[i]-1),'%',sep=''))
if(i==1){
legend('topleft',col=c(cols, rep('black',length(Max_follows))),bty='n',
lty=c(1,1,1:length(Max_follows)),inset=0.03,title = 'Endpoint',
legend = c('Time to clearance','Rate of clearance'))
legend('left',col='black',title = 'Duration of follow-up (days)',
lty=1:length(Max_follows),inset=0.03,bty='n',
legend = Max_follows)
}
}
# Fix effect size
Effect_sizes = 1.075
follow_days = lapply(c(0.5,1,2,5,10), function(x) seq(0,10,by=x))
power_rates = list()
out_path = 'Rout/frequency_follow_up.RData'
if(FORCE_RE_RUN | !file.exists(out_path)){
for(i in 1:length(follow_days)){
writeLines(sprintf('Doing simulation with %s follow-up points',
length(follow_days[[i]])))
power_rates[[i]] = compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = follow_days[[i]],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')[1,,]
}
save(power_rates, file = out_path)
} else {
load(out_path)
}
summaries = lapply(power_rates, function(x) apply(x,1,
function(x) mean(x<my_alpha)))
par(mfrow=c(1,1),las=1,cex.lab=1.3,
cex.axis=1.3,family='serif',mar=c(5,5,3,2),bty='n')
mycols = RColorBrewer::brewer.pal(length(summaries), name = 'BrBG')
plot(Sample_sizes, summaries[[1]],type='l', col=mycols[1],panel.first=grid(),
ylab='Power', xlab= 'Sample size per arm', ylim=c(0,1),lwd=3)
for(i in 2:length(summaries)){
lines(Sample_sizes, summaries[[i]],col=mycols[i],lwd=3)
}
legend('bottomright',legend = sapply(follow_days,length),col=mycols,cex=1.5,
inset=0.03,lwd=3, title='Viral load measurements over 10 days',bty='n')
Effect_sizes = 1.075
Sample_sizes = 50
Max_follow = seq(3, 21, by=1)
out_path = 'Rout/duration.RData'
Nsim = 10000
if(FORCE_RE_RUN | !file.exists(out_path)){
power_TE_follow = power_rates_follow = array(dim = c(length(Max_follow), Nsim))
# do for rate endpoint
for(mm in 1:length(Max_follow)){
power_rates_follow[mm,]=
compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follow[mm],
Nsim = Nsim,
summary_function = compute_rate,
thetas=thetas, endpoint = 'rate')[1,1,,drop=T]
}
# do for time to event endpoint
for(mm in 5:length(Max_follow)){
power_TE_follow[mm,]=
compute_pvalues(Effect_sizes = Effect_sizes,
Sample_sizes = Sample_sizes,
Follow_up_days = 0:Max_follow[mm],
Nsim = Nsim,
summary_function = compute_clearance_time,
thetas=thetas, endpoint = 'timetoevent')[1,1,,drop=T]
}
save(power_rates_follow, power_TE_follow, file = out_path)
} else {
load(file = out_path)
}
par(mfrow=c(1,1),las=1,lwd=1.5, cex.lab=1.3,cex.axis=1.3,
family='serif',mar=c(5,5,3,2),bty='n')
plot(Max_follow, apply(power_rates_follow, 1, function(x) mean(x<my_alpha)),
type='l', ylim = c(0,1), ylab='Power',panel.first=grid(),
xlab= 'Duration of follow-up',col=cols[2], lwd=3)
lines(Max_follow,apply(power_TE_follow, 1, function(x) mean(x<my_alpha)),
lwd = 3, col=cols[1])
abline(h=c(0.6,.44),v=c(10,12),lty=2)
legend('topright',legend = c('Time-to-clearance', 'Rate-of-clearance'),
col=cols,lwd=2, title = 'Endpoint', bty='n')
unlink('Comparing_time_vs_rate_cache', recursive = TRUE)
